[{"title":"从源码构建 Jetson-Perf：一步步指南","url":"/2025/02/17/%E4%BB%8E%E6%BA%90%E7%A0%81%E6%9E%84%E5%BB%BAJetson-Perf/","content":"在 NVIDIA Jetson 平台上进行性能分析时，perf 工具是不可或缺的利器。然而，由于硬件架构和内核版本的特殊性，直接使用预编译版本可能无法完全满足需求。本文将从源码开始，详细介绍如何在 Jetson Orin 和 X86 平台上构建 perf 工具，并解决编译过程中可能遇到的常见问题。\n\n一、准备工作：源码下载Jetson Orin 平台\n下载 L4T 驱动包访问 NVIDIA 开发者下载中心，搜索 Jetson Linux Driver Package (L4T)，选择与设备匹配的版本（如 R35.x 系列）。[注：需根据 Jetson 型号选择对应的版本，参考下图中的版本号。]\n获取 BSP 源码下载完成后，找到 public_sources.tbz2 文件，这是构建内核和工具链所需的基础源码包。\n\n\n\nOrin Drive 平台\n查看当前系统的核版本\nuname -r\n\n下载内核源码访问 Linux 内核镜像站，根据当前系统内核版本下载对应的源码包。例如：若内核版本为 5.15.116-rt-tegra，则下载 linux-5.15.116.tar.gz。\n\n\n\n\nX86 平台\n查看当前系统的核版本\nuname -r\n\n下载内核源码访问 Linux 内核镜像站，根据当前系统内核版本下载对应的源码包。例如：若内核版本为 5.10.0，则下载 linux-5.10.tar.gz。\n\n\n\n\n二、源码编译步骤编译环境准备sudo apt install make gcc flex bison pkg-config -y\n\n\n\nJetson Orin 编译流程tar -xjvf public_sources.tbz2 &amp;&amp; \\cd Linux_for_Tegra/source/public &amp;&amp; \\tar -xjvf kernel_src.tbz2 &amp;&amp; \\cd kernel/kernel-5.10/tools/perf &amp;&amp; \\make -j$(nproc) &amp;&amp; \\sudo make install &amp;&amp; \\./perf --version\n\n\n\nOrin Drive 编译流程tar zxvf linux-5.15.116.tar.gz &amp;&amp; \\cd linux-5.15.116/tools/perf &amp;&amp; \\make -j$(nproc) &amp;&amp; \\sudo make install &amp;&amp; \\./perf --version\n\n\n\nX86 平台编译流程\n安装依赖项X86 平台需安装以下开发库：\nsudo apt-get install build-essential flex bison python3 python3-dev \\  libelf-dev libnewt-dev libdw-dev libaudit-dev libiberty-dev \\  libunwind-dev libcap-dev libzstd-dev libnuma-dev libssl-dev \\  binutils-dev gcc-multilib liblzma-dev\n\n编译 perf\ntar zxvf linux-5.10.tar.gz &amp;&amp; \\cd linux-5.10/tools/perf &amp;&amp; \\make -j$(nproc) &amp;&amp; \\sudo make install &amp;&amp; \\./perf --version\n\n\n\n三、开启内核调试支持默认情况下，Linux 内核会限制 perf 的权限。通过以下命令解除限制：\nsudo sysctl kernel.perf_event_paranoid=-1\n\n将此设置永久生效，可将其写入 /etc/sysctl.conf。\n\n\n四、通过 perf 生成火焰图：直观分析性能瓶颈火焰图（Flame Graph）是性能分析的利器，它能以可视化方式展示程序的函数调用栈和资源占用情况。结合 perf 工具，我们可以快速生成火焰图，精准定位性能瓶颈。以下是详细操作步骤：\n1. 安装火焰图生成工具首先需要克隆 Brendan Gregg 的 FlameGraph 工具库：\ngit clone https://github.com/brendangregg/FlameGraph.gitcd FlameGraph\n\n将此工具的路径加入环境变量，或直接通过绝对路径调用脚本（如 ./FlameGraph/stackcollapse-perf.pl）。\n2. 使用 perf 采集性能数据运行目标程序，并通过 perf record 记录性能事件（如 CPU 周期、缓存失效等）：\n# 监控 CPU 使用情况（默认）sudo perf record -F 99 -a -g -- sleep 60# 或监控特定进程sudo perf record -F 99 -p &lt;PID&gt; -g -- sleep 30# 或监控具体程序sudo perf record -F 99 -g ./&lt;MY_PROGRAM&gt;\n\n\n参数说明：\n-F 99：采样频率为 99 Hz（避免与某些内核频率冲突）。\n-a：监控所有 CPU。\n-g：记录调用栈（生成火焰图必需）。\n-- sleep 60：持续采样 60 秒。\n\n\n\n3. 生成火焰图采集完成后，按以下步骤处理数据：\n# 生成 perf.data 的解析文本sudo perf script &gt; out.perf# 折叠调用栈（关键步骤）./FlameGraph/stackcollapse-perf.pl out.perf &gt; out.folded# 生成 SVG 格式火焰图./FlameGraph/flamegraph.pl out.folded &gt; flamegraph.svg\n\n4. 查看与分析火焰图用浏览器打开 flamegraph.svg，可以看到类似下图的交互式可视化结果：\n火焰图解读技巧：\n\n横向宽度：表示函数或代码路径的资源（如 CPU 时间）占用比例。\n纵向层级：表示函数调用栈的深度，顶层是正在执行的函数，下层是调用者。\n点击缩放：支持点击任意区块展开查看细节。\n高亮搜索：按 Ctrl + F 搜索关键函数名。\n\n\n\n五、常见问题解决（FAQ）Q1：编译时提示某些 Feature 未启用问题现象编译过程中出现 WARNING: ... missing xxx,某些功能将被禁用。\n解决方法\n\n查看具体错误日志：\ncat ../build/feature/test-libunwind.make.output\n\n\n根据缺失的依赖安装对应开发库。安装elf即可sudo apt install -y libelf-dev，其余Feature开启方法同理\nsudo apt install -y libelf-devsudo apt install libunwind-devsudo apt install -y libdw1sudo apt install -y elfutilssudo apt install -y libdw-devsudo apt install -y binutils-dev\n\nQ2：运行 perf 时权限不足若未设置 kernel.perf_event_paranoid，需通过 sudo 运行 perf，或按第三步永久解除限制。\n\n\n六、总结通过从源码构建 perf 工具，可以确保其与当前内核版本的完全兼容性，并启用所有高级功能。如果在编译中遇到问题，请优先检查依赖项和错误日志，大多数问题均可通过安装缺失的库解决。\n\n效果验证成功编译后，运行 perf list 可查看支持的性能监控事件。尝试使用 perf stat 或 perf record 分析程序性能。\n","categories":["blog"],"tags":["Orin","GPU","性能分析"]},{"title":"当CUDA撞上DLA暗礁：一个DLA死锁引发的蝴蝶效应与安全气囊的诞生","url":"/2025/04/19/%E5%BD%93CUDA%E6%B5%81%E6%92%9E%E4%B8%8ADLA%E6%9A%97%E7%A4%81%EF%BC%9A%E4%B8%80%E4%B8%AADLA%E6%AD%BB%E9%94%81%E5%BC%95%E5%8F%91%E7%9A%84%E8%9D%B4%E8%9D%B6%E6%95%88%E5%BA%94%E4%B8%8E%E5%AE%89%E5%85%A8%E6%B0%94%E5%9B%8A%E7%9A%84%E8%AF%9E%E7%94%9F/","content":"在 Jetson AGX Orin&#x2F;Orin-X 平台的实际运行中，CUDA 与 DLA 原本各司其职，却因并发而偶发集体“假死”——所有线程在 cudaStreamSynchronize() 阻塞中寸步难行。面对这一似乎无解的死锁暗礁，我从故障复现场景入手，定位到混合推理流中的同步点；随后排除了显存越界、流类型、DLA 降频等常见因素；最终灵感来源于“反向隔离”思路——为 GPU 与 DLA 各自配置独立的 GPU Context，并通过显式的异步拷贝与同步保证数据无缝切换。本文将以最直接的技术视角——从现象描述、排查方法到“多 Context 安全气囊”实现细节——全流程解读如何在 7×24h 压测中彻底消除死锁，实现并行推理的性能与可靠性双赢。\n\n一、问题现象1. 偶发死锁\n症状描述：单进程内，所有线程在调用 GPU 时集体“假死”——cudaStreamSynchronize() 一直阻塞，tegrastats 显示 GPU 占用率维持在某个固定值，不再波动。  \n\n复现难度：  \n\n极不稳定：有时运气极差，一周都无法触发；有时运气极好，仅需两小时即复现。  \nDLA 与 CUDA 混合推理时尤甚：DLA 推理线程先“提前几毫秒”挂死，其他线程随后也步入停滞。\n\n\n\n  \n  \n\n\n  GPU推理线程 与 DLA推理线程 同时卡死\n\n\n2. 环境特征\n硬件平台：Jetson AGX Orin 系列（最初使用 AGX Orin，后转至 Orin-X）。  \n推理流程：  \n全部模型均通过 TensorRT 的 enqueueV3() + CUDA Stream 异步执行；  \n前处理同样基于 CUDA Stream；  \n部分子图运行于 DLA，非支持算子回落至 Tensor&#x2F;Tensor Core。\n\n\n\n\n二、初步排查1. 定位死锁环节通过在各关键步骤间插入 cudaStreamSynchronize()，逐步缩小排查范围：\n\n前处理 —— 无异常；  \nTensorRT enqueueV3() —— 成功返回；  \n自定义 Plugin（HWCBGR → CHWRGB）—— 顺利完成；  \n同步点 —— 在 Plugin 之后的第一次 cudaStreamSynchronize() 挂死。\n\n2. 排除思路\n显存越界？  \n\n其中一个模型 A 曾在 2024 年出现过显存越界，但通常显存越界会触发 sticky error 并抛出 illegal memory access 而非死锁。\n\n\nBlocking vs. Non-blocking Stream？  \n\n初步猜测 DLA 可能依赖于 blocking stream，而我使用的是 non-blocking 版；最终未能证实。\n\n\nDLA 频率降频？  \n\n若 DLA 调用低于 2 Hz，会自动释放并重申请资源，导致延迟飙升。  \n提升调用频率后虽解决了降频，但死锁依旧。\n\n\n\n\n\n三、环境变更与新线索1. 从 AGX Orin 到 Orin-X\n2024 年 3 月，怀疑 AGX Orin DLA 变频机制有问题，遂放弃尝试；  \n2025 年 3 月，转战 Orin-X，DLA 频率稳定——但在并行运行其他 GPU 模型 A 时，依旧触发死锁。\n\n2. 关键“怀疑模型 A”\n模型 A 曾导致显存越界，虽然在最小化测试环境下并未复现死锁，但在系统中只要与 DLA 并行，死锁概率骤增，然而其余模型并不会导致该问题。\n单独跑 DLA、单独跑模型 A 均正常，仅并行时“相逢即死锁”。\n\n\n四、“安全气囊”诞生：多 Context 隔离策略1. 灵感来源面试一位候选人提到的 GPU 多进程中间件：  \n\n“通过截获多进程的 GPU 请求，在后端融合 context，实现时分复用，从而提升GPU利用率。”  \n\n虽然该方案与我单进程场景相悖，却激发了一个思路——反其道而行之：既然单 context 并行 DLA + GPU 会死锁，何不为它们分别提供独立 context？\n2. 实施要点\n上下文划分  \nOrin 系列拥有 2 个 DLA 引擎 + 1 个 GPU，引擎间资源隔离天然独立；  \n为 DLA 和 GPU 各自创建独立 TensorRT Context。\n\n\n内存与数据同步  \n注意：在 CUDA Context 之外，显存、Host 映射等资源也无法跨 context 共享；  \n切换 Context 时，显式 cudaMemcpyAsync() 与 cudaStreamSynchronize() 确保数据同步与完整性。\n\n\n并行执行  \nDLA 上跑模型 H；  \nGPU 上跑模型 A、B、C、D、E；\n彼此互不干扰，独立抢占各自算力。\n\n\n\n\n五、最终验证\n7×24 h 连续压测：自 2025 年 4 月以来，未再出现任何死锁。  \n蝴蝶效应终成蝶：原本令人头痛的 DLA 隐晦死锁，反而催生出一套“安全气囊”式的多 context 并行机制——既排除了模型 A 的潜在越界风险，又保障了 DLA 与 GPU 资源的稳健协同。\n\n\n六、结语当我们在深度学习推理的微观世界里拨开层层迷雾，总会发现，看似偶然的卡死背后，往往是资源管理与并发调度的微妙博弈。通过多 Context 隔离，为 DLA 与 GPU 架起了一道“安全栅栏”，既兼顾了性能，又守护了系统的可用性——这，或许就是自动驾驶推理优化的下一块基石。\n\n—— 致正在与 DLA、TensorRT、CUDA “暗礁”博弈的你  \n","categories":["blog"],"tags":["Orin","GPU"]},{"title":"轻量化部署：Xavier设备低成本运行DeepSeek+QWQ大模型","url":"/2025/03/08/%E8%BD%BB%E9%87%8F%E5%8C%96%E9%83%A8%E7%BD%B2%EF%BC%9AXavier%E8%AE%BE%E5%A4%87%E4%BD%8E%E6%88%90%E6%9C%AC%E8%BF%90%E8%A1%8CDeepSeek-QWQ%E5%A4%A7%E6%A8%A1%E5%9E%8B/","content":"在边缘设备上部署大语言模型一直被认为是算力密集型的’禁区’，但当我用一块Jetson Xavier AGX成功运行了DeepSeek-R1 14B和QWQ-32B模型时，推理速度稳定在 8 tokens&#x2F;s (DeepSeek-R1 14B) &#x2F; 4 tokens&#x2F;s (QWQ-32B) 以上！本文将分享从环境配置到量化优化的完整方案，证明边缘设备同样可以成为轻量化AI的舞台。\n\n一、硬件配置与挑战分析：\n设备选型：NVIDIA Jetson Xavier AGX\n核心参数：512核Volta GPU + 8核Carmel CPU &#x2F; 32GB RAM &#x2F; 32GB eMMC\n系统环境：JetPack 5.1.3 (Ubuntu 20.04) &#x2F; CUDA 11.4 &#x2F; TensorRT 8.5.2\n功耗模式：默认10W切换至MAXN模式\n\n为什么选择DeepSeek &amp; QWQ？\n\n\n维度\nQWQ-32B\nDeepSeek-R1-14B\n\n\n\n参数量\n32B\n14B\n\n\n架构类型\nDecoder-Only（密集型）\nMoE（混合专家，16选2）\n\n\n上下文窗口\n训练支持32K\n原生支持16K\n\n\nXavier显存占用\n20~22GB\n6~8GB\n\n\n推理速度\n4.3 tokens&#x2F;s\n8.7 tokens&#x2F;s\n\n\n优势\n长文本理解能力突出工业领域知识深度优化动态稀疏激活降低计算负载\n代码生成能力领先多轮对话响应快MoE架构灵活适配多任务\n\n\n部署三大难关\n显存墙：FP16模型加载即需14GB+显存 → Jetson统一内存\n架构差异：ARM平台与x86服务器的库兼容性问题 → Docker容器化\n计算瓶颈：Token生成速度&lt;5tokens&#x2F;s时用户体验差 → 流水线优化\n\n二、技术实现全流程拆解阶段一：构建ARM适配的基础环境核心挑战：NVIDIA Jetson Xavier的ARM架构与常规x86服务器存在三大差异：\n\n指令集差异：ARMv8.2与x86_64的SIMD指令集不兼容（如NEON vs AVX512）\n内存管理差异：Jetson采用CPU-GPU统一内存架构（UMA），与传统PCIe分体式显存管理模式冲突\n软件生态差异：PyTorch等框架的ARM预编译包缺失关键算子支持\n\n技术路线：采用「容器化隔离+定制化编译」双轨策略：\n\n硬件抽象层：通过 jetson-containers 项目预构建CUDA、cuDNN等核心组件的ARM64版本容器镜像\n依赖解耦：针对JetPack 5.1.3的特定版本（CUDA 11.4 + TensorRT 8.5.2），使用镜像解决动态库符号链接问题\n\n关键实现：\n\n更新python版本：jetson-containers代码依赖Python 3.9（functools.cache），需要将原有python3.8更新为python3.9版本\n\n  sudo rm /usr/bin/python3 &amp;&amp; \\sudo ln -s /usr/bin/python3.9 /usr/bin/python3\n\n安装jetson-containers：\n\n  git clone https://github.com/dusty-nv/jetson-containersbash jetson-containers/install.sh\n\n设置Docker Runtime：  修改/etc/docker/daemon.json配置，并指定default-runtime\n\n  &#123;    &quot;runtimes&quot;: &#123;        &quot;nvidia&quot;: &#123;            &quot;path&quot;: &quot;nvidia-container-runtime&quot;,            &quot;runtimeArgs&quot;: []        &#125;    &#125;,    &quot;default-runtime&quot;: &quot;nvidia&quot;&#125;\n  重启docker服务  sudo systemctl restart docker  验证配置更新  sudo docker info | grep &#x27;Default Runtime&#x27;\n\n显示docker没有root权限：\nsudo usermod -aG docker $USER\n阶段二：构建Ollama基础镜像\n修改Dockerfile  修改jetson-containers/packages/llm/ollama/Dockerfile为以下内容\n\n  #---# name: ollama# group: llm# config: config.py# depends: cuda# requires: &#x27;&gt;=34.1.0&#x27;# docs: docs.md#---ARG BASE_IMAGE \\    CMAKE_CUDA_ARCHITECTURES \\    CUDA_VERSION_MAJOR \\    JETPACK_VERSION \\    OLLAMA_REPO \\    OLLAMA_BRANCH \\    GOLANG_VERSION \\    CMAKE_VERSION# build the runtime containerFROM $&#123;BASE_IMAGE&#125;ARG JETPACK_VERSION \\    CUDA_VERSION_MAJOREXPOSE 11434ENV OLLAMA_HOST=0.0.0.0 \\    OLLAMA_MODELS=/data/models/ollama/models \\    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \\    LD_LIBRARY_PATH=/usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/cuda/include:$&#123;LD_LIBRARY_PATH&#125; \\    JETSON_JETPACK=$&#123;JETPACK_VERSION&#125; \\    CUDA_VERSION_MAJOR=$&#123;CUDA_VERSION_MAJOR&#125;RUN apt-get update &amp;&amp; \\    apt install -y curl  &amp;&amp; \\    rm -rf /var/lib/apt/lists/* &amp;&amp; \\    apt-get cleanCOPY nv_tegra_release /etc/nv_tegra_release#ADD https://api.github.com/repos/ollama/ollama/branches/main /tmp/ollama_version.jsonRUN curl -H &quot;Authorization: token $&#123;GITHUB_TOKEN&#125;&quot; \\    -o /tmp/ollama_version.json \\    https://api.github.com/repos/ollama/ollama/branches/mainRUN curl -fsSL https://ollama.com/install.sh | shRUN rm /usr/bin/python || true &amp;&amp; \\    ln -s /usr/bin/python3 /usr/bin/pythonCOPY start_ollama /CMD /start_ollama &amp;&amp; /bin/bash\n\n\n构建镜像\n\n  jetson-containers build ollama\n\n\n验证构建镜像\n\n  docker images | grep ollama\n\n阶段三：模型下载 &amp; 推理\n进入Container环境\n\n  jetson-containers run --name ollama $(autotag ollama)\n\n\n模型下载\n\n  ollama pull qwq:latestollama pull deepseek-r1:14b\n\n\n模型推理验证\n\n  ollama run qwq:latest\n  查看GPU使用率  jtop\n\njtop安装：\nsudo pip3 install -U jetson-stats &amp;&amp; \\sudo systemctl restart jtop.service\n阶段四（可选）：K3S部署与服务搭建待补充\n三、性能实测：数据不说谎模型对比实验\n\n\n模型\n显存\n待机功耗\n运行功耗\nprompt eval rate\neval rate\n\n\n\ndeepseek-r1:14b\n10.5G\n5.1w\n43.7 w\n144.21 tokens&#x2F;s\n8.11 tokens&#x2F;s\n\n\nQwQ:32b\n21.1G\n5.4 w\n47.6 w\n6.04 tokens&#x2F;s\n3.93 tokens&#x2F;s\n\n\ndeepseek-r1:14b\n  \n  \n\n\n\n\nQwQ:32b\n  \n  \n\n\n\n\n成本效益对比\n\n\n方案\n硬件成本\n每月费用\n延迟\n数据出境风险\n\n\n\n云端API\n¥ 0\n¥1600\n200ms\n高\n\n\nXavier本地\n¥ 3000\n¥18\n20ms\n零\n\n\n应用场景：这不是玩具，是生产力案例1：openweb-ui知识库本地问答待补充\n","categories":["blog"],"tags":["GPU","Xavier"]}]