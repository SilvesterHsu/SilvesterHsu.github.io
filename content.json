{"posts":[{"title":"从源码构建 Jetson-Perf：一步步指南","text":"在 NVIDIA Jetson 平台上进行性能分析时，perf 工具是不可或缺的利器。然而，由于硬件架构和内核版本的特殊性，直接使用预编译版本可能无法完全满足需求。本文将从源码开始，详细介绍如何在 Jetson Orin 和 X86 平台上构建 perf 工具，并解决编译过程中可能遇到的常见问题。 一、准备工作：源码下载Jetson Orin 平台 下载 L4T 驱动包访问 NVIDIA 开发者下载中心，搜索 Jetson Linux Driver Package (L4T)，选择与设备匹配的版本（如 R35.x 系列）。[注：需根据 Jetson 型号选择对应的版本，参考下图中的版本号。] 获取 BSP 源码下载完成后，找到 public_sources.tbz2 文件，这是构建内核和工具链所需的基础源码包。 Orin Drive 平台 查看当前系统的核版本 1uname -r 下载内核源码访问 Linux 内核镜像站，根据当前系统内核版本下载对应的源码包。例如：若内核版本为 5.15.116-rt-tegra，则下载 linux-5.15.116.tar.gz。 X86 平台 查看当前系统的核版本 1uname -r 下载内核源码访问 Linux 内核镜像站，根据当前系统内核版本下载对应的源码包。例如：若内核版本为 5.10.0，则下载 linux-5.10.tar.gz。 二、源码编译步骤编译环境准备1sudo apt install make gcc flex bison pkg-config -y Jetson Orin 编译流程12345678910tar -xjvf public_sources.tbz2 &amp;&amp; \\cd Linux_for_Tegra/source/public &amp;&amp; \\tar -xjvf kernel_src.tbz2 &amp;&amp; \\cd kernel/kernel-5.10/tools/perf &amp;&amp; \\make -j$(nproc) &amp;&amp; \\sudo make install &amp;&amp; \\./perf --version Orin Drive 编译流程12345678tar zxvf linux-5.15.116.tar.gz &amp;&amp; \\cd linux-5.15.116/tools/perf &amp;&amp; \\make -j$(nproc) &amp;&amp; \\sudo make install &amp;&amp; \\./perf --version X86 平台编译流程 安装依赖项X86 平台需安装以下开发库： 1234sudo apt-get install build-essential flex bison python3 python3-dev \\ libelf-dev libnewt-dev libdw-dev libaudit-dev libiberty-dev \\ libunwind-dev libcap-dev libzstd-dev libnuma-dev libssl-dev \\ binutils-dev gcc-multilib liblzma-dev 编译 perf 1234567tar zxvf linux-5.10.tar.gz &amp;&amp; \\cd linux-5.10/tools/perf &amp;&amp; \\make -j$(nproc) &amp;&amp; \\sudo make install &amp;&amp; \\./perf --version 三、开启内核调试支持默认情况下，Linux 内核会限制 perf 的权限。通过以下命令解除限制： 1sudo sysctl kernel.perf_event_paranoid=-1 将此设置永久生效，可将其写入 /etc/sysctl.conf。 四、通过 perf 生成火焰图：直观分析性能瓶颈火焰图（Flame Graph）是性能分析的利器，它能以可视化方式展示程序的函数调用栈和资源占用情况。结合 perf 工具，我们可以快速生成火焰图，精准定位性能瓶颈。以下是详细操作步骤： 1. 安装火焰图生成工具首先需要克隆 Brendan Gregg 的 FlameGraph 工具库： 12git clone https://github.com/brendangregg/FlameGraph.gitcd FlameGraph 将此工具的路径加入环境变量，或直接通过绝对路径调用脚本（如 ./FlameGraph/stackcollapse-perf.pl）。 2. 使用 perf 采集性能数据运行目标程序，并通过 perf record 记录性能事件（如 CPU 周期、缓存失效等）： 123456# 监控 CPU 使用情况（默认）sudo perf record -F 99 -a -g -- sleep 60# 或监控特定进程sudo perf record -F 99 -p &lt;PID&gt; -g -- sleep 30# 或监控具体程序sudo perf record -F 99 -g ./&lt;MY_PROGRAM&gt; 参数说明： -F 99：采样频率为 99 Hz（避免与某些内核频率冲突）。 -a：监控所有 CPU。 -g：记录调用栈（生成火焰图必需）。 -- sleep 60：持续采样 60 秒。 3. 生成火焰图采集完成后，按以下步骤处理数据： 12345678# 生成 perf.data 的解析文本sudo perf script &gt; out.perf# 折叠调用栈（关键步骤）./FlameGraph/stackcollapse-perf.pl out.perf &gt; out.folded# 生成 SVG 格式火焰图./FlameGraph/flamegraph.pl out.folded &gt; flamegraph.svg 4. 查看与分析火焰图用浏览器打开 flamegraph.svg，可以看到类似下图的交互式可视化结果： 火焰图解读技巧： 横向宽度：表示函数或代码路径的资源（如 CPU 时间）占用比例。 纵向层级：表示函数调用栈的深度，顶层是正在执行的函数，下层是调用者。 点击缩放：支持点击任意区块展开查看细节。 高亮搜索：按 Ctrl + F 搜索关键函数名。 五、常见问题解决（FAQ）Q1：编译时提示某些 Feature 未启用问题现象编译过程中出现 WARNING: ... missing xxx,某些功能将被禁用。 解决方法 查看具体错误日志： 1cat ../build/feature/test-libunwind.make.output 根据缺失的依赖安装对应开发库。安装elf即可sudo apt install -y libelf-dev，其余Feature开启方法同理 123456sudo apt install -y libelf-devsudo apt install libunwind-devsudo apt install -y libdw1sudo apt install -y elfutilssudo apt install -y libdw-devsudo apt install -y binutils-dev Q2：运行 perf 时权限不足若未设置 kernel.perf_event_paranoid，需通过 sudo 运行 perf，或按第三步永久解除限制。 六、总结通过从源码构建 perf 工具，可以确保其与当前内核版本的完全兼容性，并启用所有高级功能。如果在编译中遇到问题，请优先检查依赖项和错误日志，大多数问题均可通过安装缺失的库解决。 效果验证成功编译后，运行 perf list 可查看支持的性能监控事件。尝试使用 perf stat 或 perf record 分析程序性能。","link":"/2025/02/17/%E4%BB%8E%E6%BA%90%E7%A0%81%E6%9E%84%E5%BB%BAJetson-Perf/"},{"title":"轻量化部署：Xavier设备低成本运行DeepSeek+QWQ大模型","text":"在边缘设备上部署大语言模型一直被认为是算力密集型的’禁区’，但当我用一块Jetson Xavier AGX成功运行了DeepSeek-R1 14B和QWQ-32B模型时，推理速度稳定在 8 tokens/s (DeepSeek-R1 14B) / 4 tokens/s (QWQ-32B) 以上！本文将分享从环境配置到量化优化的完整方案，证明边缘设备同样可以成为轻量化AI的舞台。 一、硬件配置与挑战分析： 设备选型：NVIDIA Jetson Xavier AGX 核心参数：512核Volta GPU + 8核Carmel CPU / 32GB RAM / 32GB eMMC 系统环境：JetPack 5.1.3 (Ubuntu 20.04) / CUDA 11.4 / TensorRT 8.5.2 功耗模式：默认10W切换至MAXN模式 为什么选择DeepSeek &amp; QWQ？ 维度 QWQ-32B DeepSeek-R1-14B 参数量 32B 14B 架构类型 Decoder-Only（密集型） MoE（混合专家，16选2） 上下文窗口 训练支持32K 原生支持16K Xavier显存占用 20~22GB 6~8GB 推理速度 4.3 tokens/s 8.7 tokens/s 优势 长文本理解能力突出工业领域知识深度优化动态稀疏激活降低计算负载 代码生成能力领先多轮对话响应快MoE架构灵活适配多任务 部署三大难关 显存墙：FP16模型加载即需14GB+显存 → Jetson统一内存 架构差异：ARM平台与x86服务器的库兼容性问题 → Docker容器化 计算瓶颈：Token生成速度&lt;5tokens/s时用户体验差 → 流水线优化 二、技术实现全流程拆解阶段一：构建ARM适配的基础环境核心挑战：NVIDIA Jetson Xavier的ARM架构与常规x86服务器存在三大差异： 指令集差异：ARMv8.2与x86_64的SIMD指令集不兼容（如NEON vs AVX512） 内存管理差异：Jetson采用CPU-GPU统一内存架构（UMA），与传统PCIe分体式显存管理模式冲突 软件生态差异：PyTorch等框架的ARM预编译包缺失关键算子支持 技术路线：采用「容器化隔离+定制化编译」双轨策略： 硬件抽象层：通过 jetson-containers 项目预构建CUDA、cuDNN等核心组件的ARM64版本容器镜像 依赖解耦：针对JetPack 5.1.3的特定版本（CUDA 11.4 + TensorRT 8.5.2），使用镜像解决动态库符号链接问题 关键实现： 更新python版本：jetson-containers代码依赖Python 3.9（functools.cache），需要将原有python3.8更新为python3.9版本 12sudo rm /usr/bin/python3 &amp;&amp; \\sudo ln -s /usr/bin/python3.9 /usr/bin/python3 安装jetson-containers： 12git clone https://github.com/dusty-nv/jetson-containersbash jetson-containers/install.sh 设置Docker Runtime： 修改/etc/docker/daemon.json配置，并指定default-runtime 12345678910{ &quot;runtimes&quot;: { &quot;nvidia&quot;: { &quot;path&quot;: &quot;nvidia-container-runtime&quot;, &quot;runtimeArgs&quot;: [] } }, &quot;default-runtime&quot;: &quot;nvidia&quot;} 重启docker服务 1sudo systemctl restart docker 验证配置更新 1sudo docker info | grep 'Default Runtime' 显示docker没有root权限： 1sudo usermod -aG docker $USER 阶段二：构建Ollama基础镜像 修改Dockerfile 修改jetson-containers/packages/llm/ollama/Dockerfile为以下内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#---# name: ollama# group: llm# config: config.py# depends: cuda# requires: '&gt;=34.1.0'# docs: docs.md#---ARG BASE_IMAGE \\ CMAKE_CUDA_ARCHITECTURES \\ CUDA_VERSION_MAJOR \\ JETPACK_VERSION \\ OLLAMA_REPO \\ OLLAMA_BRANCH \\ GOLANG_VERSION \\ CMAKE_VERSION# build the runtime containerFROM ${BASE_IMAGE}ARG JETPACK_VERSION \\ CUDA_VERSION_MAJOREXPOSE 11434ENV OLLAMA_HOST=0.0.0.0 \\ OLLAMA_MODELS=/data/models/ollama/models \\ PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \\ LD_LIBRARY_PATH=/usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/cuda/include:${LD_LIBRARY_PATH} \\ JETSON_JETPACK=${JETPACK_VERSION} \\ CUDA_VERSION_MAJOR=${CUDA_VERSION_MAJOR}RUN apt-get update &amp;&amp; \\ apt install -y curl &amp;&amp; \\ rm -rf /var/lib/apt/lists/* &amp;&amp; \\ apt-get cleanCOPY nv_tegra_release /etc/nv_tegra_release#ADD https://api.github.com/repos/ollama/ollama/branches/main /tmp/ollama_version.jsonRUN curl -H &quot;Authorization: token ${GITHUB_TOKEN}&quot; \\ -o /tmp/ollama_version.json \\ https://api.github.com/repos/ollama/ollama/branches/mainRUN curl -fsSL https://ollama.com/install.sh | shRUN rm /usr/bin/python || true &amp;&amp; \\ ln -s /usr/bin/python3 /usr/bin/pythonCOPY start_ollama /CMD /start_ollama &amp;&amp; /bin/bash 构建镜像 1jetson-containers build ollama 验证构建镜像 1docker images | grep ollama 阶段三：模型下载 &amp; 推理 进入Container环境 1jetson-containers run --name ollama $(autotag ollama) 模型下载 12ollama pull qwq:latestollama pull deepseek-r1:14b 模型推理验证 1ollama run qwq:latest 查看GPU使用率 1jtop jtop安装： 12sudo pip3 install -U jetson-stats &amp;&amp; \\sudo systemctl restart jtop.service 阶段四（可选）：K3S部署与服务搭建待补充 三、性能实测：数据不说谎模型对比实验 模型 显存 待机功耗 运行功耗 prompt eval rate eval rate deepseek-r1:14b 10.5G 5.1w 43.7 w 144.21 tokens/s 8.11 tokens/s QwQ:32b 21.1G 5.4 w 47.6 w 6.04 tokens/s 3.93 tokens/s deepseek-r1:14b QwQ:32b 成本效益对比 方案 硬件成本 每月费用 延迟 数据出境风险 云端API ¥ 0 ¥1600 200ms 高 Xavier本地 ¥ 3000 ¥18 20ms 零 应用场景：这不是玩具，是生产力案例1：openweb-ui知识库本地问答待补充","link":"/2025/03/08/%E8%BD%BB%E9%87%8F%E5%8C%96%E9%83%A8%E7%BD%B2%EF%BC%9AXavier%E8%AE%BE%E5%A4%87%E4%BD%8E%E6%88%90%E6%9C%AC%E8%BF%90%E8%A1%8CDeepSeek-QWQ%E5%A4%A7%E6%A8%A1%E5%9E%8B/"}],"tags":[{"name":"Orin","slug":"Orin","link":"/tags/Orin/"},{"name":"GPU","slug":"GPU","link":"/tags/GPU/"},{"name":"性能分析","slug":"性能分析","link":"/tags/%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"},{"name":"Xavier","slug":"Xavier","link":"/tags/Xavier/"}],"categories":[{"name":"blog","slug":"blog","link":"/categories/blog/"}],"pages":[{"title":"Silvester Hsu","text":"Who am IMy name is Silvester Hsu, and I specialize in model inference and GPU optimization, with a focus on autonomous driving technologies. Currently, My primary research interests include optimizing the performance of models for autonomous driving applications, improving the computational efficiency of deep learning models and fine-tuning system-level GPU performance to meet the high demands of real-time, safety-critical applications. I graduated with a Master’s degree in Computer Science from University of Sheffield where I conducted research in machine learning and Nvidia optimization techniques. In my work, I strive to balance theoretical elegance with real-world applicability. I am passionate about creating scalable, efficient systems that can make a tangible difference. However, I am also acutely aware of the trade-offs between theory and implementation, and often reflect on how optimization can help overcome some of these challenges. Career JourneyI was initially drawn to technology due to its ability to solve real-world problems at scale. However, my early experiences with traditional computer science techniques made me question the existing paradigms. My curiosity led me to machine learning and AI, fields I now consider both challenging and immensely rewarding. While pursuing my Master’s, I started engaging with open-source projects and attending GPU optimization in machine learning, which allowed me to quickly catch up with the latest advancements in AI. These experiences, along with collaborations with researchers and practitioners, have shaped my expertise in building both state-of-the-art models and practical engineering solutions. About This SiteThis website was created to document my learning journey, share insights from my work in machine learning, and present some of my projects and research. It’s a place for me to explore new ideas, dive into complex technical topics, and contribute to the broader AI community. The main objectives of this site are: Discuss the latest advancements in GPU optimization for machine learning, with a special focus on autonomous driving. Share practical strategies for improving computational efficiency in deep learning. Present personal projects, research, and experiments. Reflect on key milestones and achievements in my career. Please note, all views expressed on this site are my own and do not represent those of my current or past employers. CitationsIf you would like to cite any of the content on this site or my open-source projects on GitHub, please refer to the URLs provided. I will ensure they remain permanent, unless GitHub or my hosting provider makes significant changes in the future. Contact MeIf you have any questions, comments, or feedback about my blog posts or projects, feel free to leave a comment under the respective post or open an issue in my GitHub repositories. I highly encourage discussions that can help others. For more private inquiries, you can reach me via email.","link":"/index.html"},{"title":"Silvester Hsu","text":"I am a developer dedicated to efficient algorithms and GPU programming, with a focus on research and application in computer vision, deep learning, and high-performance computing. I have extensive experience in parallel computing, image processing, and inference engine optimization. I specialize in performance optimization using CUDA and have a deep understanding of GPU memory management and acceleration of deep learning frameworks. In my GitHub repository, you can find open-source projects across multiple domains, ranging from GPU memory management tools and image distortion correction algorithms to efficient model inference engine optimizations. I have contributed code to several deep learning projects and successfully improved inference speed and computational efficiency. Tech Stack Programming Languages: C++, Python, Bash GPU Programming: CUDA, TensorRT, cuDNN Deep Learning Frameworks: TensorFlow, PyTorch, ONNX Image Processing: OpenCV, Computer Vision (CV) Databases: SQLite Operating Systems: Linux (Ubuntu), Windows Tools &amp; Environments: Git, Docker, Jenkins, CMake Performance Optimization: SIMD, Multithreading, High-Performance Computing (HPC) I have a strong interest in algorithm optimization, computational graph design, and GPU acceleration, particularly in applications such as autonomous driving and image recognition. I look forward to connecting and collaborating with like-minded developers to push the boundaries of cutting-edge technology.","link":"/about/index.html"}]}